{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/r3dmaohong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img, w, b):\n",
    "    return( tf.nn.relu( tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1,1,1,1], padding='SAME'), b) ) )\n",
    "def max_pool(img, k):\n",
    "    return(tf.nn.max_pool(img, ksize = [1,k,k,1], strides=[1,k,k,1], padding='SAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 5000\n",
    "batch_size = 128\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_classes = 10\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "_X = tf.reshape(x, shape=[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first layer\n",
    "wc1 = tf.Variable(tf.random_normal([5,5,1,32])) # patch size, input channel, output channel\n",
    "bc1 = tf.Variable(tf.random_normal([32])) # 32 feature maps?\n",
    "\n",
    "conv1 = conv2d(_X, wc1, bc1)\n",
    "conv1 = max_pool(conv1, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "conv1 = tf.nn.dropout(conv1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second layer\n",
    "wc2 = tf.Variable(tf.random_normal([5,5,32,64])) #\n",
    "bc2 = tf.Variable(tf.random_normal([64]))\n",
    "\n",
    "conv2 = conv2d(conv1, wc2, bc2)\n",
    "conv2 = max_pool(conv2, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout\n",
    "conv2 = tf.nn.dropout(conv2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected layer?\n",
    "wd1 = tf.Variable(tf.random_normal([7*7*64, 1024])) # 28/2/2 = 7\n",
    "bd1 = tf.Variable(tf.random_normal([1024]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = tf.reshape(conv2, [-1, wd1.get_shape().as_list()[0]])\n",
    "dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, wd1), bd1))\n",
    "dense1 = tf.nn.dropout(dense1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "wout = tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "bout = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.add(tf.matmul(dense1, wout), bout)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001, Loss= 83024.718750, Training Accuracy= 0.18750\n",
      "Epoch 00100, Loss= 9485.380859, Training Accuracy= 0.49219\n",
      "Epoch 00200, Loss= 3739.992676, Training Accuracy= 0.60156\n",
      "Epoch 00300, Loss= 1384.069824, Training Accuracy= 0.67969\n",
      "Epoch 00400, Loss= 1261.957520, Training Accuracy= 0.68750\n",
      "Epoch 00500, Loss= 1459.150757, Training Accuracy= 0.67188\n",
      "Epoch 00600, Loss= 878.726501, Training Accuracy= 0.72656\n",
      "Epoch 00700, Loss= 815.576721, Training Accuracy= 0.68750\n",
      "Epoch 00800, Loss= 711.362427, Training Accuracy= 0.71094\n",
      "Epoch 00900, Loss= 618.091919, Training Accuracy= 0.74219\n",
      "Epoch 01000, Loss= 491.558533, Training Accuracy= 0.74219\n",
      "Epoch 01100, Loss= 617.497192, Training Accuracy= 0.78125\n",
      "Epoch 01200, Loss= 460.298309, Training Accuracy= 0.74219\n",
      "Epoch 01300, Loss= 617.620850, Training Accuracy= 0.72656\n",
      "Epoch 01400, Loss= 393.846008, Training Accuracy= 0.81250\n",
      "Epoch 01500, Loss= 368.432404, Training Accuracy= 0.75000\n",
      "Epoch 01600, Loss= 394.334778, Training Accuracy= 0.79688\n",
      "Epoch 01700, Loss= 250.576431, Training Accuracy= 0.80469\n",
      "Epoch 01800, Loss= 235.962097, Training Accuracy= 0.82812\n",
      "Epoch 01900, Loss= 362.203308, Training Accuracy= 0.79688\n",
      "Epoch 02000, Loss= 361.419189, Training Accuracy= 0.84375\n",
      "Epoch 02100, Loss= 162.106689, Training Accuracy= 0.87500\n",
      "Epoch 02200, Loss= 399.204742, Training Accuracy= 0.81250\n",
      "Epoch 02300, Loss= 276.168854, Training Accuracy= 0.84375\n",
      "Epoch 02400, Loss= 189.333862, Training Accuracy= 0.85156\n",
      "Epoch 02500, Loss= 227.042450, Training Accuracy= 0.83594\n",
      "Epoch 02600, Loss= 111.177841, Training Accuracy= 0.89062\n",
      "Epoch 02700, Loss= 111.847717, Training Accuracy= 0.89844\n",
      "Epoch 02800, Loss= 157.033173, Training Accuracy= 0.91406\n",
      "Epoch 02900, Loss= 163.228622, Training Accuracy= 0.91406\n",
      "Epoch 03000, Loss= 188.464508, Training Accuracy= 0.89062\n",
      "Epoch 03100, Loss= 170.499054, Training Accuracy= 0.86719\n",
      "Epoch 03200, Loss= 217.130447, Training Accuracy= 0.89844\n",
      "Epoch 03300, Loss= 125.149704, Training Accuracy= 0.89844\n",
      "Epoch 03400, Loss= 18.048866, Training Accuracy= 0.96875\n",
      "Epoch 03500, Loss= 128.233765, Training Accuracy= 0.91406\n",
      "Epoch 03600, Loss= 73.061996, Training Accuracy= 0.91406\n",
      "Epoch 03700, Loss= 111.507843, Training Accuracy= 0.90625\n",
      "Epoch 03800, Loss= 90.880249, Training Accuracy= 0.89062\n",
      "Epoch 03900, Loss= 67.433098, Training Accuracy= 0.93750\n",
      "Epoch 04000, Loss= 86.281952, Training Accuracy= 0.90625\n",
      "Epoch 04100, Loss= 127.197815, Training Accuracy= 0.89844\n",
      "Epoch 04200, Loss= 75.201370, Training Accuracy= 0.92969\n",
      "Epoch 04300, Loss= 47.247070, Training Accuracy= 0.91406\n",
      "Epoch 04400, Loss= 25.195541, Training Accuracy= 0.94531\n",
      "Epoch 04500, Loss= 67.956779, Training Accuracy= 0.92969\n",
      "Epoch 04600, Loss= 13.712547, Training Accuracy= 0.97656\n",
      "Epoch 04700, Loss= 43.157719, Training Accuracy= 0.92188\n",
      "Epoch 04800, Loss= 72.574028, Training Accuracy= 0.91406\n",
      "Epoch 04900, Loss= 49.605537, Training Accuracy= 0.92969\n",
      "Epoch 05000, Loss= 20.298851, Training Accuracy= 0.95312\n",
      "==================================================\n",
      "Finished.\n",
      "==================================================\n",
      "Testing Accuracy: 0.9282\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size=batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y:batch_ys, keep_prob:dropout})\n",
    "        \n",
    "        if ((epoch+1) % display_step==0) | (epoch==0):\n",
    "            acc = sess.run(accuracy, feed_dict={x:batch_xs, y:batch_ys, keep_prob:1.})\n",
    "            loss = sess.run(cost, feed_dict={x:batch_xs, y:batch_ys, keep_prob:1.})\n",
    "            print(\"Epoch \" + \"%05d\"%(epoch+1) + \", Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    print(\"=\"*50)\n",
    "    print(\"Finished.\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
